{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColoringGAN_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygs2BHEEeDd"
      },
      "source": [
        "\n",
        "The main notebook for Coloring GAN using VGG16 weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaIsn7h2F-vq"
      },
      "source": [
        "!unzip -q '/content/drive/My Drive/BE_project/final_sample.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nuPLSMEGIay",
        "outputId": "5c6adfea-9335-4c3a-e134-c062cfd41b2b"
      },
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Restrict TensorFlow to only use the fourth GPU\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "        \n",
        "#tf.compat.v1.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usi9E7x2GlkK"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array,ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXmZQjtTE1VP"
      },
      "source": [
        "This part is only for displaying the time for epochs in a formatted fashion. Do not play around over here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUYk4F3WHjXB"
      },
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VAFhr-VHl_X",
        "outputId": "d6d97c5f-44f7-4567-b7a9-1682ec68f0de"
      },
      "source": [
        "# Generation resolution - Must be square \n",
        "# Training data is also scaled to this.\n",
        "# Note GENERATE_RES 4 or higher  \n",
        "# will blow Google CoLab's memory and have not\n",
        "# been tested extensivly.\n",
        "GENERATE_RES = 3 # Generation resolution factor \n",
        "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
        "GENERATE_SQUARE = 64 # rows/cols (should be square)\n",
        "GEN_IMAGE_CHANNELS = 3\n",
        "INPUT_IMAGE_CHANNELS = 1\n",
        "\n",
        "# Preview image \n",
        "PREVIEW_ROWS = 1\n",
        "PREVIEW_COLS = 2\n",
        "PREVIEW_MARGIN = 8\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 1\n",
        "\n",
        "# Configuration\n",
        "if(not os.path.exists('/content/drive/My Drive/BE_project/output/colorised/')):\n",
        "  path = '/content/drive/My Drive/BE_project/output/colorised/'\n",
        "  os.makedirs(path)\n",
        "  print(f\"Created new directory: {path}\")\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/BE_project/output/colorised/'\n",
        "TRAIN_PATH = '/content/data.zip/'\n",
        "\n",
        "log_file = '/content/drive/My Drive/BE_project/output/training_history.csv'\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will generate 64px square images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHT7D9ghFAF-"
      },
      "source": [
        "These are the data generators used for producing batches of colored and subsequent black and white images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N7LlaV-I_7h",
        "outputId": "36aa569f-9783-4d2c-bd0a-0908b0e0f4dd"
      },
      "source": [
        "bw_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        ")\n",
        "\n",
        "bw_image_generator = bw_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    class_mode=None,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=16,\n",
        "    target_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n",
        "    seed=123,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "cl_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255\n",
        ")\n",
        "\n",
        "cl_image_generator = cl_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    class_mode=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    target_size=(GENERATE_SQUARE, GENERATE_SQUARE),\n",
        "    seed=123,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24 images belonging to 1 classes.\n",
            "Found 24 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3_PB1OLFHYP"
      },
      "source": [
        "We build our generator network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNOQwhvJlxh"
      },
      "source": [
        "def build_generator(channels, image_shape = (720,720,1)):\n",
        "    input_tensor = Input(shape=image_shape)\n",
        "    X = Conv2D(filters = 3, kernel_size=3, padding='same', name=\"input_conv\")(input_tensor)\n",
        "    #X = UpSampling2D(size=(4,4), name='upsample_input')(X)\n",
        "    X = Conv2DTranspose(3, (1,1), strides=(4,4), input_shape=(64,64, 3), name='input_conv2d_transpose')(X)\n",
        "\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet',input_shape=(256,256,3))\n",
        "    \n",
        "    \n",
        "    for i in range(1,len(vgg16.layers)):\n",
        "        if(vgg16.layers[i].name == 'block3_pool'):\n",
        "            break\n",
        "        X = vgg16.layers[i](X)\n",
        "\n",
        "    X =  Conv2D(filters = channels, kernel_size=3, padding='same', name='output_conv')(X)\n",
        "    X = Activation('tanh', name='output_activation')(X)\n",
        "\n",
        "    model = Model(inputs = input_tensor, outputs = X, name='Generator')\n",
        "    \n",
        "    custom_layers = set(['input_conv','upsample_input','output_conv','output_activation','input_conv2d_transpose'])\n",
        "    \n",
        "    for layer in model.layers:\n",
        "        if(layer.name not in custom_layers):\n",
        "            layer.trainable = False\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_FLrYq7FKrc"
      },
      "source": [
        "We build the discriminator network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "394BFmlJL04e"
      },
      "source": [
        "def build_discriminator(image_shape=(720,720,3)):\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet',input_shape=image_shape)\n",
        "    for layer in vgg16.layers:\n",
        "      layer.trainable = False\n",
        "    X = Dropout(0.25)(vgg16.output)\n",
        "    X = Conv2D(filters = 256, kernel_size=3, strides=1, padding='same')(X)\n",
        "    X = BatchNormalization(momentum=0.8)(X)\n",
        "    X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "    X = Dropout(0.25)(vgg16.output)\n",
        "    X = Conv2D(filters = 512, kernel_size=3, strides=1, padding='same')(X)\n",
        "    X = BatchNormalization(momentum=0.8)(X)\n",
        "    X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "    X = Dropout(0.25)(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "    model = Model(inputs = vgg16.input, outputs = X, name='Discriminator')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHDJiaLWFPaD"
      },
      "source": [
        "Let's create an instance of network optimizers. We'll use them later on to apply weights using gradient tape. For now, we'll just initialize them with appropriate names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jRziddQJQd"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "992hAGW1F7pt"
      },
      "source": [
        "We see how our generator network performs with initialized weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "KNYNhvm-QVqU",
        "outputId": "8ee9080e-db51-4396-f0c9-5dc8d732d865"
      },
      "source": [
        "generator = build_generator(GEN_IMAGE_CHANNELS,(GENERATE_SQUARE,GENERATE_SQUARE,INPUT_IMAGE_CHANNELS))\n",
        "\n",
        "bw_image = bw_image_generator.next()\n",
        "\n",
        "generated_image = generator(bw_image, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5ff5c57d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEgBnzLGGDkF"
      },
      "source": [
        "Our discriminator provides us with little to no result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uU-2nl0QalL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecb66cc-d1c4-469b-846c-8e9dc368b7e1"
      },
      "source": [
        "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,GEN_IMAGE_CHANNELS)\n",
        "\n",
        "discriminator = build_discriminator(image_shape)\n",
        "decision = discriminator(generated_image)\n",
        "print (decision[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.5530127], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvUMINk4GH9Z"
      },
      "source": [
        "We're setting up the loss function for our generator and discriminator. That's the log loss or the binary crossentropy loss defined accordingly in the report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVpE3_UcgCuK"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgrw4NdMGSXS"
      },
      "source": [
        "The train step is where we'll process a batch of images and calculate the loss of generator and discriminator. We'll apply the gradient descent values to the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbSGp5ZRhSUC"
      },
      "source": [
        "@tf.function\n",
        "def train_step(bw_images, cl_images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        #Get the generated image batch by passing the grayscale images through the generator\n",
        "        generated_images = generator(bw_images, training=True)\n",
        "        \n",
        "        real_output = discriminator(cl_images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "        #Calculate the losses of the networks\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        \n",
        "        #Get the gradients using gradient tape\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        \n",
        "        #Apply the gradients so update variables\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        \n",
        "        return gen_loss, disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfAZfDYtlese"
      },
      "source": [
        "#This cell contains all the \"callback\" type functionalities\n",
        "def save_images(cnt,bw_images, cl_images):\n",
        "    image_array = np.full(( \n",
        "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "      255, dtype=np.uint8)\n",
        "\n",
        "    generated_images = generator.predict(bw_images)\n",
        "\n",
        "    generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "    original_image = cl_images[0]\n",
        "\n",
        "    final_images = np.array([generated_images[0],original_image])\n",
        "\n",
        "    image_count = 0\n",
        "    for row in range(PREVIEW_ROWS):\n",
        "        for col in range(PREVIEW_COLS):\n",
        "            r = row * (GENERATE_SQUARE+8) + PREVIEW_MARGIN\n",
        "            c = col * (GENERATE_SQUARE+8) + PREVIEW_MARGIN\n",
        "            image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
        "                = final_images[image_count] * 255\n",
        "            image_count += 1\n",
        "\n",
        "\n",
        "    output_path = os.path.join(DATA_PATH,'output')\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
        "    im = Image.fromarray(image_array)\n",
        "    im.save(filename)\n",
        "\n",
        "\n",
        "def csv_logger(dictionary, field_names, file_name, header=False):\n",
        "  with open(file_name, 'a') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "    if(header):\n",
        "      writer.writeheader()\n",
        "    writer.writerow(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjpWCoGhd-j"
      },
      "source": [
        "def train(gen_generator, disc_generator, epochs, steps_per_epoch):\n",
        "    start = time.time()\n",
        "    metrics = {'gen_loss':[], 'disc_loss':[]}\n",
        "    field_names = ['Epoch', 'gen_loss', 'disc_loss']\n",
        "\n",
        "    header = True\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        if(epoch>0):\n",
        "          header = False\n",
        "            \n",
        "        gen_loss_list = []\n",
        "        disc_loss_list = []\n",
        "        \n",
        "        bw_batch = []\n",
        "        cl_batch = []\n",
        "        \n",
        "        steps = 0\n",
        "        \n",
        "        for bw_imagebatch, cl_imagebatch in zip(gen_generator,disc_generator):\n",
        "            if(steps>steps_per_epoch):\n",
        "                break\n",
        "            if(len(bw_batch)<8):\n",
        "                for i in range(bw_imagebatch.shape[0]):\n",
        "                    bw_batch.append(bw_imagebatch[i])\n",
        "                    cl_batch.append(cl_imagebatch[i])\n",
        "            t = train_step(bw_imagebatch, cl_imagebatch)\n",
        "            gen_loss_list.append(t[0])\n",
        "            disc_loss_list.append(t[1])\n",
        "            steps+=1\n",
        "\n",
        "        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
        "        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
        "\n",
        "        metrics['gen_loss'].append(g_loss.numpy())\n",
        "        metrics['disc_loss'].append(d_loss.numpy())\n",
        "\n",
        "        #Log the epoch losses\n",
        "        log = {'Epoch': epoch+1, 'gen_loss': g_loss.numpy(), 'disc_loss': d_loss.numpy()}\n",
        "        csv_logger(log, field_names, log_file, header)\n",
        "\n",
        "        epoch_elapsed = time.time()-epoch_start\n",
        "        \n",
        "        print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss}, epoch_time={hms_string(epoch_elapsed)}')\n",
        "        save_images(epoch,np.array(bw_batch), np.array(cl_batch))\n",
        "\n",
        "    elapsed = time.time()-start\n",
        "    print (f'Training time: {hms_string(elapsed)}')\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mENU89Dlhhxl",
        "outputId": "e076e49d-e9e8-489b-eede-e7343ab737f2"
      },
      "source": [
        "print(generator.summary())\n",
        "print(\"\\n\\n\")\n",
        "print(discriminator.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
            "_________________________________________________________________\n",
            "input_conv (Conv2D)          (None, 64, 64, 3)         30        \n",
            "_________________________________________________________________\n",
            "input_conv2d_transpose (Conv (None, 256, 256, 3)       12        \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "output_conv (Conv2D)         (None, 64, 64, 3)         6915      \n",
            "_________________________________________________________________\n",
            "output_activation (Activatio (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 1,742,445\n",
            "Trainable params: 6,957\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "\n",
            "\n",
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 17,078,593\n",
            "Trainable params: 2,362,881\n",
            "Non-trainable params: 14,715,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1zgeBA8eno0m",
        "outputId": "dba3d5c5-056f-499a-d3f4-eee75d9ac2c9"
      },
      "source": [
        "#Plot model only when necessary\n",
        "\n",
        "'''\n",
        "tf.keras.utils.plot_model(\n",
        "    generator,\n",
        "    to_file = 'generator.png',\n",
        "    show_shapes = True,\n",
        "    show_layer_names = True,\n",
        "    expand_nested = True,\n",
        "    dpi = 96\n",
        ")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntf.keras.utils.plot_model(\\n    generator,\\n    to_file = 'generator.png',\\n    show_shapes = True,\\n    show_layer_names = True,\\n    expand_nested = True,\\n    dpi = 96\\n)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4yrXrJWnobZd",
        "outputId": "1a3a11a9-855b-4d7e-b175-544819ca2d99"
      },
      "source": [
        "#Plot model only when necessary\n",
        "\n",
        "'''\n",
        "tf.keras.utils.plot_model(\n",
        "    discriminator,\n",
        "    to_file = 'discriminator.png',\n",
        "    show_shapes = True,\n",
        "    show_layer_names = True,\n",
        "    expand_nested = True,\n",
        "    dpi = 96\n",
        ")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntf.keras.utils.plot_model(\\n    discriminator,\\n    to_file = 'discriminator.png',\\n    show_shapes = True,\\n    show_layer_names = True,\\n    expand_nested = True,\\n    dpi = 96\\n)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmyLRPwvolXv",
        "outputId": "f8c4be1c-9ef8-48d8-8b9a-933fa1971c29"
      },
      "source": [
        "steps_per_epoch = int(np.ceil(bw_image_generator.n/bw_image_generator.batch_size))\n",
        "\n",
        "history = train(bw_image_generator, cl_image_generator, EPOCHS, steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, gen loss=1.3730478286743164,disc loss=0.9025211334228516, epoch_time=0:00:16.04\n",
            "Epoch 2, gen loss=2.4606151580810547,disc loss=0.25695088505744934, epoch_time=0:00:00.94\n",
            "Epoch 3, gen loss=2.2224819660186768,disc loss=0.3222353756427765, epoch_time=0:00:00.94\n",
            "Epoch 4, gen loss=2.114732027053833,disc loss=0.4901310205459595, epoch_time=0:00:00.94\n",
            "Epoch 5, gen loss=2.2321150302886963,disc loss=0.36624157428741455, epoch_time=0:00:00.94\n",
            "Epoch 6, gen loss=3.299806594848633,disc loss=0.1793256402015686, epoch_time=0:00:00.94\n",
            "Epoch 7, gen loss=3.5032966136932373,disc loss=0.07995928078889847, epoch_time=0:00:00.94\n",
            "Epoch 8, gen loss=3.963414430618286,disc loss=0.06751134246587753, epoch_time=0:00:00.94\n",
            "Epoch 9, gen loss=4.099547863006592,disc loss=0.048386115580797195, epoch_time=0:00:00.97\n",
            "Epoch 10, gen loss=4.6059722900390625,disc loss=0.0349009707570076, epoch_time=0:00:00.96\n",
            "Epoch 11, gen loss=4.399816036224365,disc loss=0.03078393079340458, epoch_time=0:00:00.94\n",
            "Epoch 12, gen loss=4.950029373168945,disc loss=0.02342352271080017, epoch_time=0:00:00.94\n",
            "Epoch 13, gen loss=5.14292049407959,disc loss=0.016677439212799072, epoch_time=0:00:00.93\n",
            "Epoch 14, gen loss=5.100558757781982,disc loss=0.02021058090031147, epoch_time=0:00:00.93\n",
            "Epoch 15, gen loss=5.079256534576416,disc loss=0.019016604870557785, epoch_time=0:00:00.94\n",
            "Epoch 16, gen loss=5.264873504638672,disc loss=0.022153513506054878, epoch_time=0:00:00.94\n",
            "Epoch 17, gen loss=5.20117712020874,disc loss=0.013491771183907986, epoch_time=0:00:00.94\n",
            "Epoch 18, gen loss=5.954837799072266,disc loss=0.012281094677746296, epoch_time=0:00:00.94\n",
            "Epoch 19, gen loss=5.859674453735352,disc loss=0.010434827767312527, epoch_time=0:00:00.95\n",
            "Epoch 20, gen loss=5.495555400848389,disc loss=0.008483601734042168, epoch_time=0:00:00.94\n",
            "Epoch 21, gen loss=5.54209566116333,disc loss=0.010041382163763046, epoch_time=0:00:00.95\n",
            "Epoch 22, gen loss=5.730444431304932,disc loss=0.009261303581297398, epoch_time=0:00:00.94\n",
            "Epoch 23, gen loss=5.74439001083374,disc loss=0.008246652781963348, epoch_time=0:00:00.95\n",
            "Epoch 24, gen loss=6.405007839202881,disc loss=0.007804611697793007, epoch_time=0:00:00.95\n",
            "Epoch 25, gen loss=6.260195255279541,disc loss=0.006161004304885864, epoch_time=0:00:00.95\n",
            "Epoch 26, gen loss=5.928712844848633,disc loss=0.010515698231756687, epoch_time=0:00:00.95\n",
            "Epoch 27, gen loss=4.977375030517578,disc loss=0.022254781797528267, epoch_time=0:00:00.95\n",
            "Epoch 28, gen loss=6.832559108734131,disc loss=0.007224523928016424, epoch_time=0:00:00.94\n",
            "Epoch 29, gen loss=6.700711727142334,disc loss=0.005614524241536856, epoch_time=0:00:00.95\n",
            "Epoch 30, gen loss=6.84625768661499,disc loss=0.006588693708181381, epoch_time=0:00:00.95\n",
            "Epoch 31, gen loss=6.622613906860352,disc loss=0.00480652367696166, epoch_time=0:00:00.94\n",
            "Epoch 32, gen loss=6.8093695640563965,disc loss=0.005987563636153936, epoch_time=0:00:00.94\n",
            "Epoch 33, gen loss=6.248560428619385,disc loss=0.004578320775181055, epoch_time=0:00:00.95\n",
            "Epoch 34, gen loss=6.713575839996338,disc loss=0.006095657590776682, epoch_time=0:00:00.95\n",
            "Epoch 35, gen loss=6.941053867340088,disc loss=0.003122580237686634, epoch_time=0:00:00.94\n",
            "Epoch 36, gen loss=5.507705211639404,disc loss=0.010280362330377102, epoch_time=0:00:00.94\n",
            "Epoch 37, gen loss=7.575479984283447,disc loss=0.0032782412599772215, epoch_time=0:00:00.94\n",
            "Epoch 38, gen loss=6.911785125732422,disc loss=0.0032823828514665365, epoch_time=0:00:00.94\n",
            "Epoch 39, gen loss=6.9333953857421875,disc loss=0.004421951714903116, epoch_time=0:00:00.94\n",
            "Epoch 40, gen loss=7.102317810058594,disc loss=0.003948709461838007, epoch_time=0:00:00.94\n",
            "Epoch 41, gen loss=6.990149974822998,disc loss=0.003137958934530616, epoch_time=0:00:00.95\n",
            "Epoch 42, gen loss=7.106105327606201,disc loss=0.0030087244231253862, epoch_time=0:00:00.95\n",
            "Epoch 43, gen loss=7.048898220062256,disc loss=0.0038157005328685045, epoch_time=0:00:00.95\n",
            "Epoch 44, gen loss=7.256449222564697,disc loss=0.0025547186378389597, epoch_time=0:00:00.95\n",
            "Epoch 45, gen loss=7.295707702636719,disc loss=0.002533676102757454, epoch_time=0:00:00.94\n",
            "Epoch 46, gen loss=7.12893533706665,disc loss=0.0022254467476159334, epoch_time=0:00:00.95\n",
            "Epoch 47, gen loss=7.45965576171875,disc loss=0.0027437619864940643, epoch_time=0:00:00.94\n",
            "Epoch 48, gen loss=6.756898403167725,disc loss=0.0029242951422929764, epoch_time=0:00:00.94\n",
            "Epoch 49, gen loss=7.327579498291016,disc loss=0.0021712370216846466, epoch_time=0:00:00.95\n",
            "Epoch 50, gen loss=7.286843776702881,disc loss=0.004310014192014933, epoch_time=0:00:00.94\n",
            "Training time: 0:01:29.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upUfMQN6orZd"
      },
      "source": [
        "generator.save(os.path.join(DATA_PATH,\"color_generator.h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}